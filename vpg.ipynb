{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T12:31:51.643099Z",
     "start_time": "2022-01-07T12:31:49.900204Z"
    }
   },
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cartpole Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T12:31:52.743793Z",
     "start_time": "2022-01-07T12:31:52.713251Z"
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rendered window env might stay unresponsive and some say this is due to jupyter notebook visualization problems.  \n",
    "Looking for a way to solve this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using GIF looks like one solution : https://rrbb014.tistory.com/44#openai-gym%EC%9D%84-jupyter-notebook%ED%99%98%EA%B2%BD%EC%97%90%EC%84%9C-%EC%8B%A4%ED%96%89%ED%95%98%EA%B8%B0-headless-playing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T12:31:55.154001Z",
     "start_time": "2022-01-07T12:31:55.128077Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "env.reset()\n",
    "# let's see 10 timesteps with random action\n",
    "for _ in range(10):\n",
    "    # env.render()\n",
    "    observation, reward, done, info = env.step(env.action_space.sample())\n",
    "    print(observation, reward, done, info)\n",
    "    if done:\n",
    "        break\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the whole training is going on, the graph will be the mean survived timesteps for each epochs.\n",
    "\n",
    "And the loss graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T12:31:59.322278Z",
     "start_time": "2022-01-07T12:31:58.460604Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot([1,2,2,2,3,4,5,5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model(for policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T12:32:09.310395Z",
     "start_time": "2022-01-07T12:32:05.319749Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.categorical import Categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Linear NN for the policy. It is from a code in CS285 lecture 3, except it uses softmax at the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T12:32:10.446910Z",
     "start_time": "2022-01-07T12:32:10.429589Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size=4, output_size=2):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 32)\n",
    "        self.fc2 = nn.Linear(32, 32)\n",
    "        self.fc3 = nn.Linear(32, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x), dim=-1)\n",
    "        return x      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T12:32:10.794593Z",
     "start_time": "2022-01-07T12:32:10.680813Z"
    }
   },
   "outputs": [],
   "source": [
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "# example of input\n",
    "print(net(torch.tensor([[1., 2., 3., 4.], [2., 3., 2., 2.]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathematics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\nabla_\\theta J(\\theta) \\approx \\frac{1}{N} \\sum_{i=1}^{N} \\sum_{t=1}^{T} \\nabla_\\theta \\log{\\pi_\\theta \\left( a_{i,t} | s_{i,t} \\right)}  \\left( \\sum_{t^\\prime=t}^{T} r\\left( s_{i,t}, a_{i,t} \\right) \\right) \\\\\n",
    "J(\\theta) = E_{\\tau~p_\\theta(\\tau)}\\left[ \\sum_{t}r(s_t, a_t) \\right] \\approx \\frac{1}{N}\\sum_i\\sum_{t}r(s_{i,t}, a_{i,t}) \\\\\n",
    "\\tilde{J}(\\theta) \\approx \\frac{1}{N}\\sum_{i=1}^N\\sum_{t=1}^T \\log{\\pi_\\theta \\left( a_{i,t} | s_{i,t} \\right)} \\hat{Q}_{i,t} \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$-\\tilde{J}(\\theta)$ will be used as the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\theta \\leftarrow \\theta + \\alpha \\nabla_\\theta J(\\theta) \\\\ = \\theta - \\alpha \\nabla_\\theta (-J(\\theta))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The codes that will run to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T12:32:14.533047Z",
     "start_time": "2022-01-07T12:32:14.523572Z"
    }
   },
   "outputs": [],
   "source": [
    "# number of samples(trajectories) for each iteration\n",
    "N = 1000\n",
    "\n",
    "# T(max length of the trajectory)\n",
    "max_traj_len = 100 \n",
    "\n",
    "# The policy object\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run the policy to create N samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All information about samples will be stored in a list `samples`\n",
    "\n",
    "The final shape of the list `samples` will be\n",
    "\n",
    "__[nth_trajectory] [state, action, reward, q_value(reward to go)]__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T12:37:01.171213Z",
     "start_time": "2022-01-07T12:36:52.523535Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm # to visualize the progress\n",
    "\n",
    "# new samples for every update, because VPG is an On-policy algorithm\n",
    "samples = []\n",
    "\n",
    "for sample_i in tqdm(range(N)):\n",
    "    # initial state\n",
    "    observation = env.reset()\n",
    "    one_traj = []\n",
    "    for traj_step in range(max_traj_len):\n",
    "        # rolling out the policy to get actions\n",
    "        softmax_value = net(torch.from_numpy(observation)).detach()\n",
    "        action = Categorical(softmax_value).sample().item()\n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "        # append the [s, a, r] in a list\n",
    "        one_traj.append([observation, action, reward])\n",
    "        observation = new_observation\n",
    "        if done or traj_step == (max_traj_len - 1):\n",
    "            # append the trajectory in a list\n",
    "            samples.append(one_traj)\n",
    "            break\n",
    "\n",
    "print('one trajectory looks like this')\n",
    "for traj in samples[0]:\n",
    "    print(traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Q-values(reward to go)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{Q}_{i,t} = \\sum^{T}_{t^\\prime=t}{r\\left( s_{i, t^\\prime} , a_{i, t^\\prime}\\right )}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T06:41:49.847738Z",
     "start_time": "2022-01-07T06:41:49.813728Z"
    }
   },
   "outputs": [],
   "source": [
    "# Getting the q-values(reward to go)\n",
    "q_values = []\n",
    "for sample in samples:\n",
    "    temp = []\n",
    "    for i in range(len(sample)):\n",
    "        q = 0\n",
    "        for t in range(i, len(sample)):\n",
    "            q += sample[t][2] # Adding the reward for time t at current trajectory\n",
    "        temp.append(q)\n",
    "    q_values.append(temp)\n",
    "\n",
    "# appending the q_values to the 'samples' list\n",
    "for i in range(len(q_values)):\n",
    "    for j in range(len(q_values[i])):\n",
    "        samples[i][j].append(q_values[i][j])\n",
    "        \n",
    "        \n",
    "        \n",
    "print('Now, one trajectory looks like this')\n",
    "for traj in samples[0]:\n",
    "    print(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T06:41:50.107588Z",
     "start_time": "2022-01-07T06:41:50.061603Z"
    }
   },
   "outputs": [],
   "source": [
    "# shape of the list 'samples' => [trajectory][state, action, reward, q_value(reward to go)]\n",
    "# making a list(soon will be changed to tensors) for actions, states, q_values\n",
    "\n",
    "actions = []\n",
    "states = []\n",
    "q_values = []\n",
    "for sample in samples:\n",
    "    for state, action, reward, q_value in sample:\n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        q_values.append(q_value)\n",
    "\n",
    "actions = torch.from_numpy(np.array(actions))\n",
    "states = torch.from_numpy(np.array(states))\n",
    "q_values = torch.from_numpy(np.array(q_values))\n",
    "net_values = net(states).max(dim=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tilde{J}(\\theta) \\approx \\frac{1}{N}\\sum_{i=1}^N\\sum_{t=1}^T \\log{\\pi_\\theta \\left( a_{i,t} | s_{i,t} \\right)} \\hat{Q}_{i,t} \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T06:43:14.561589Z",
     "start_time": "2022-01-07T06:43:14.555942Z"
    }
   },
   "outputs": [],
   "source": [
    "q_values.shape, net_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T06:25:07.550185Z",
     "start_time": "2022-01-07T06:25:07.512871Z"
    }
   },
   "outputs": [],
   "source": [
    "# loss function is -(J tilde) (on the equation above)\n",
    "def loss_fn(net_val, q_val):\n",
    "    return -(torch.sum(torch.log(net_val) * q_val)) / N\n",
    "\n",
    "loss = loss_fn(net_values, q_values)\n",
    "\n",
    "# loss = F.cross_entropy(net(states), actions)\n",
    "\n",
    "\n",
    "# using Adam optimizer (because in the lecture it was mentioned to be okay)\n",
    "# the learning rate is from the codes of lecture 3\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All the codes for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T13:00:09.604155Z",
     "start_time": "2022-01-07T12:39:47.773140Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [20:21<00:00,  4.07s/it]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.distributions.categorical import Categorical\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size=4, output_size=2):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 32)\n",
    "        self.fc2 = nn.Linear(32, 32)\n",
    "        self.fc3 = nn.Linear(32, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x), dim=-1)\n",
    "        return x  \n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "N = 1000\n",
    "max_traj_len = 100 # T\n",
    "net = Net()\n",
    "# number of iterations\n",
    "epoch_size = 300\n",
    "\n",
    "def loss_fn(net_val, q_val):\n",
    "    return -(torch.sum(torch.log(net_val) * q_val)) / N\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "# to record the progress\n",
    "lasted_times = [] # a list for mean lasted time for each sample\n",
    "losses = []\n",
    "\n",
    "# Learning starts here\n",
    "for _ in tqdm(range(epoch_size)):\n",
    "    samples = [] # new samples, because VPG is on policy algo\n",
    "    \n",
    "    # a list for lasted time for each sample\n",
    "    one_epoch_lasted_times = []\n",
    "    for sample_i in range(N):\n",
    "        # initial state\n",
    "        observation = env.reset()\n",
    "        one_traj = []\n",
    "        for traj_step in range(max_traj_len):\n",
    "            # Use the distribution, sample!!\n",
    "            # \n",
    "            softmax_value = net(torch.from_numpy(observation)).detach()\n",
    "            action = Categorical(softmax_value).sample().item()\n",
    "            new_observation, reward, done, info = env.step(action)\n",
    "            one_traj.append([observation, action, reward])\n",
    "            \n",
    "            observation = new_observation\n",
    "            if done or traj_step == (max_traj_len - 1):\n",
    "                samples.append(one_traj)\n",
    "                one_epoch_lasted_times.append(traj_step + 1)\n",
    "                break\n",
    "    \n",
    "    # appending the mean lasted time for each trajectory\n",
    "    lasted_times.append(sum(one_epoch_lasted_times) / len(one_epoch_lasted_times))\n",
    "                \n",
    "    # Getting the q-values(reward to go)\n",
    "    q_values = []\n",
    "    for sample in samples:\n",
    "        temp = []\n",
    "        for i in range(len(sample)):\n",
    "            q = 0\n",
    "            for t in range(i, len(sample)):\n",
    "                q += sample[t][2]\n",
    "            temp.append(q)\n",
    "        q_values.append(temp)\n",
    "    \n",
    "    # appending the q values to the samples list\n",
    "    for i in range(len(q_values)):\n",
    "        for j in range(len(q_values[i])):\n",
    "            samples[i][j].append(q_values[i][j])\n",
    "    \n",
    "    # sample shape => [trajectory][state, action, reward, q_value(reward to go)]\n",
    "    # make torch.tensors for actions, states, q_values\n",
    "    actions = []\n",
    "    states = []\n",
    "    q_values = []\n",
    "    for sample in samples:\n",
    "        for state, action, reward, q_value in sample:\n",
    "            states.append(state)\n",
    "            actions.append(action)\n",
    "            q_values.append(q_value)\n",
    "\n",
    "    actions = torch.from_numpy(np.array(actions))\n",
    "    states = torch.from_numpy(np.array(states))\n",
    "    q_values = torch.from_numpy(np.array(q_values))\n",
    "    net_values = net(states).max(dim=1).values\n",
    "    \n",
    "    loss = loss_fn(net_val=net_values, q_val=q_values)\n",
    "    losses.append(loss.data.detach())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the lasted time for Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T13:00:13.109607Z",
     "start_time": "2022-01-07T13:00:12.283773Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(lasted_times);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T13:00:17.767217Z",
     "start_time": "2022-01-07T13:00:17.564806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size=4, output_size=2):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 32)\n",
    "        self.fc2 = nn.Linear(32, 32)\n",
    "        self.fc3 = nn.Linear(32, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x), dim=-1)\n",
    "        return x  \n",
    "\n",
    "device = \"cuda\"\n",
    "    \n",
    "env = gym.make('CartPole-v0')\n",
    "N = 1000\n",
    "max_traj_len = 100 # T\n",
    "net = Net().to(device)\n",
    "# number of iterations\n",
    "epoch_size = 300\n",
    "\n",
    "def loss_fn(net_val, q_val):\n",
    "    return -(torch.sum(torch.log(net_val) * q_val)) / N\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "# to record the progress\n",
    "lasted_times = [] # a list for mean lasted time for each sample\n",
    "losses = []\n",
    "\n",
    "# Learning starts here\n",
    "for _ in tqdm(range(epoch_size)):\n",
    "    samples = [] # new samples, because VPG is on policy algo\n",
    "    \n",
    "    # a list for lasted time for each sample\n",
    "    one_epoch_lasted_times = []\n",
    "    for sample_i in range(N):\n",
    "        # initial state\n",
    "        observation = env.reset()\n",
    "        one_traj = []\n",
    "        for traj_step in range(max_traj_len):\n",
    "            action = net(torch.from_numpy(observation).to(device)).cpu().detach().numpy().argmax()\n",
    "            new_observation, reward, done, info = env.step(action)\n",
    "            one_traj.append([observation, action, reward])\n",
    "            observation = new_observation\n",
    "            if done or traj_step == (max_traj_len - 1):\n",
    "                samples.append(one_traj)\n",
    "                one_epoch_lasted_times.append(traj_step + 1)\n",
    "                break\n",
    "    \n",
    "    # appending the mean lasted time for each trajectory\n",
    "    lasted_times.append(sum(one_epoch_lasted_times) / len(one_epoch_lasted_times))\n",
    "                \n",
    "    # Getting the q-values(reward to go)\n",
    "    q_values = []\n",
    "    for sample in samples:\n",
    "        temp = []\n",
    "        for i in range(len(sample)):\n",
    "            q = 0\n",
    "            for t in range(i, len(sample)):\n",
    "                q += sample[t][2]\n",
    "            temp.append(q)\n",
    "        q_values.append(temp)\n",
    "    \n",
    "    # appending the q values to the samples list\n",
    "    for i in range(len(q_values)):\n",
    "        for j in range(len(q_values[i])):\n",
    "            samples[i][j].append(q_values[i][j])\n",
    "    \n",
    "    # sample shape => [trajectory][state, action, reward, q_value(reward to go)]\n",
    "    # make torch.tensors for actions, states, q_values\n",
    "    actions = []\n",
    "    states = []\n",
    "    q_values = []\n",
    "    for sample in samples:\n",
    "        for state, action, reward, q_value in sample:\n",
    "            states.append(state)\n",
    "            actions.append(action)\n",
    "            q_values.append(q_value)\n",
    "\n",
    "    actions = torch.from_numpy(np.array(actions)).to(device)\n",
    "    states = torch.from_numpy(np.array(states)).to(device)\n",
    "    q_values = torch.from_numpy(np.array(q_values)).to(device)\n",
    "    net_values = net(states).max(dim=1).values\n",
    "    \n",
    "    loss = loss_fn(net_val=net_values, q_val=q_values)\n",
    "    losses.append(loss.data.detach())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    \n",
    "print(lasted_times)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
